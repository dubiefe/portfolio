{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":119855,"databundleVersionId":14338739,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Emilie Dubief","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"# Introduction\n\nText Classification is the process of sorting text data into different categories depending on what the data contains. The categories can be multiple, yet here we will use Binary classification for the data. This is a task in NLP (Natural Language Processing), several methods can be used. From traditional machine learning methods like Logistic Regression, or even Transfer Learning approaches.\n\nIn order to find the best approach for our problem, let's recap what we are dealing with.\n\nHere, we work with emails that can be either spam or not spam. Thus, we need to build a binary text classification model. The data is split in two files, a training file and a testing file. We will then use the training file for training and validation, and the testing file for the submission file.\n\nFirst, you will see the final methodology applied for this problem alongside the previous algorithms I used. Then, a summary of all the results I had for each trial. Finally, a small conclusion and all the references used in this notebook.","metadata":{}},{"cell_type":"markdown","source":"# Table of content\n\n* [Methodology - NLP Model](#methodology)\n* [Results](#results)\n* [Conclusion](#conclusion)\n* [References](#references)","metadata":{}},{"cell_type":"code","source":"!pip install -q --upgrade transformers huggingface_hub\n\nimport pandas as pd\npd.set_option('display.max_rows', 36)\npd.set_option(\"display.max_colwidth\", 150)\n\nseed = 42\nimport numpy as np\nnp.random.seed(seed)\n\nfrom sklearn.model_selection import train_test_split\n\n# Regex\nimport re\n\n# Naive Bayes\nfrom sklearn.naive_bayes import MultinomialNB\n\n# LSTM\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Transfer Learning (RoBERTa)\nimport torch\nfrom datasets import Dataset\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n\n# competition metric for local evaluation\nfrom sklearn.metrics import matthews_corrcoef\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T11:50:21.799055Z","iopub.execute_input":"2025-12-06T11:50:21.799381Z","iopub.status.idle":"2025-12-06T11:51:25.056800Z","shell.execute_reply.started":"2025-12-06T11:50:21.799358Z","shell.execute_reply":"2025-12-06T11:51:25.055681Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Methodology <a class=\"anchor\"  id=\"methodology\"></a>\n\nIn this section, you will be able to see all the different steps I took to achieve the building of my final model.\n\n## Read in the training data\n\nThe first thing to do was to read the data from the train.csv files, containing a sample of spam and not spam emails.","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/u-tad-spam-not-spam-2025-edition/train.csv\", index_col = \"row_id\")\n\nX = train[\"text\"]        # Content of the emails\ny = train[\"spam_label\"]  # Labels: Spam or Not-Spam\n\n# Splitting the data for training and validation\nraw_X_train, raw_X_val, raw_y_train, raw_y_val = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T11:51:30.330398Z","iopub.execute_input":"2025-12-06T11:51:30.331165Z","iopub.status.idle":"2025-12-06T11:51:30.572005Z","shell.execute_reply.started":"2025-12-06T11:51:30.331128Z","shell.execute_reply":"2025-12-06T11:51:30.570689Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data cleaning\n\nThen, I cleaned the data to remove insignificant data in the emails, such as repetitive labels.\n\nThis cleaning process is not used in the final model because it was not useful to increase the score, yet it was necessary for the first algorithms used.","metadata":{}},{"cell_type":"code","source":"# # Cleaning data\n# def clean_text(text):\n#     text = re.sub(r'Subject: ', '', text)  # remove Subject: \n#     text = re.sub(r're : ', '', text)      # remove re: \n#     text = re.sub(r'\\n', '', text)         # remove \\n\n#     return text\n\n# cleaned_X_train = raw_X_train.apply(clean_text).tolist()\n# cleaned_X_val = raw_X_val.apply(clean_text).tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T11:51:33.887633Z","iopub.execute_input":"2025-12-06T11:51:33.887949Z","iopub.status.idle":"2025-12-06T11:51:33.942002Z","shell.execute_reply.started":"2025-12-06T11:51:33.887927Z","shell.execute_reply":"2025-12-06T11:51:33.940948Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Convertion for tranfer learning\n\nThis step is for the final algorithm used: Transfer Learning. Here, we only need to convert the data we have into a dataset to use it with the functions related to the algorithm. The content is not changing, only the type.","metadata":{}},{"cell_type":"code","source":"# Convert into Dataframes\ntrain_df = pd.DataFrame({\n    \"text\": raw_X_train.values,\n    \"label\": raw_y_train.values\n})\n\nval_df = pd.DataFrame({\n    \"text\": raw_X_val.values,\n    \"label\": raw_y_val.values\n})\n\n# Convert to HuggingFace Dataset\ntrain_ds = Dataset.from_pandas(train_df)\nval_ds = Dataset.from_pandas(val_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T11:52:08.813056Z","iopub.execute_input":"2025-12-06T11:52:08.813377Z","iopub.status.idle":"2025-12-06T11:52:08.874487Z","shell.execute_reply.started":"2025-12-06T11:52:08.813354Z","shell.execute_reply":"2025-12-06T11:52:08.873574Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Tokenisation\n\nThe next step is to separate each email into tokens. The idea here is to split the emails for the model to analyse better the data.","metadata":{}},{"cell_type":"code","source":"max_len = 128   \n\n## Transfer learning\nmodel_name = \"distilbert-base-uncased\"\n\ntokenizer = AutoTokenizer.from_pretrained(\n    model_name,\n    add_prefix_space=False,\n    truncation_side=\"right\"\n)\n\ndef tokenize(batch):\n    return tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n\nX_train = train_ds.map(tokenize, batched=True)\nX_val = val_ds.map(tokenize, batched=True)\n\nX_train = X_train.rename_column(\"label\", \"labels\")\nX_val   = X_val.rename_column(\"label\", \"labels\")\n\nX_train.set_format(\"torch\")\nX_val.set_format(\"torch\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T11:52:13.274106Z","iopub.execute_input":"2025-12-06T11:52:13.274437Z","iopub.status.idle":"2025-12-06T11:52:16.849500Z","shell.execute_reply.started":"2025-12-06T11:52:13.274412Z","shell.execute_reply":"2025-12-06T11:52:16.848560Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## NLP model\n\nThen, we need to build the model with the pre-trained model distilbert-base-uncased, to do some transfer learning and better our model.\n\nAfter that, we train our model with all our data.","metadata":{}},{"cell_type":"code","source":"## Transfer Learning (BERT)\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n\nimport os\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    eval_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=5,\n    logging_steps=10,          \n    disable_tqdm=False         \n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=X_train,\n    eval_dataset=X_val\n)\n\nprint(\"Starting training...\")\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T11:52:23.107910Z","iopub.execute_input":"2025-12-06T11:52:23.108855Z","iopub.status.idle":"2025-12-06T11:52:33.122114Z","shell.execute_reply.started":"2025-12-06T11:52:23.108820Z","shell.execute_reply":"2025-12-06T11:52:33.120786Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Make prediction\n\nHere, we test our model with the validation data we kept, and we print the accuracy and the matthews coef to see how it did.","metadata":{}},{"cell_type":"code","source":"# Make prediction on validation data\npreds = trainer.predict(X_val)\ny_pred_val = preds.predictions.argmax(axis=1)\n\n# Print results\nprint(\"Accuracy :\", accuracy_score(raw_y_val, y_pred_val))\nprint(\"Matthews coef:\", matthews_corrcoef(raw_y_val, y_pred_val))\nprint(classification_report(raw_y_val, y_pred_val))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T13:19:24.989970Z","iopub.status.idle":"2025-12-04T13:19:24.991473Z","shell.execute_reply.started":"2025-12-04T13:19:24.991282Z","shell.execute_reply":"2025-12-04T13:19:24.991308Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Real data to test the model on\n\nIn this section, we only use the model we trained with the real data for the submission.\n\n### This is the test data that you are asked to make predictions for","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/u-tad-spam-not-spam-2025-edition/test.csv\", index_col = \"row_id\")\n\nraw_X_test = test[\"text\"]\n\ntest_ds = Dataset.from_pandas(pd.DataFrame({\"text\": raw_X_test.values}))\n\ndef tokenize(batch):\n    return tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n\ntest_ds = test_ds.map(tokenize, batched=True)\ntest_ds.set_format(\"torch\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T13:19:24.992938Z","iopub.status.idle":"2025-12-04T13:19:24.993554Z","shell.execute_reply.started":"2025-12-04T13:19:24.993387Z","shell.execute_reply":"2025-12-04T13:19:24.993404Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"preds_test = trainer.predict(test_ds)\ny_pred = preds_test.predictions.argmax(axis=1)\n\nprint(y_pred[:10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T13:19:24.995001Z","iopub.status.idle":"2025-12-04T13:19:24.995738Z","shell.execute_reply.started":"2025-12-04T13:19:24.995583Z","shell.execute_reply":"2025-12-04T13:19:24.995597Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Submit your predictions in a `submission.csv` file for scoring on the [leaderboard](https://www.kaggle.com/competitions/u-tad-spam-not-spam-2025-edition/leaderboard)\nTo submit your notebook click on **Submit to competition** and then **Submit**.","metadata":{}},{"cell_type":"code","source":"# do not modify this code\nsubmission = pd.read_csv(\"/kaggle/input/u-tad-spam-not-spam-2025-edition/sample_submission.csv\")\nsubmission[\"spam_label\"] = y_pred\nsubmission.to_csv('submission.csv',index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T13:19:24.996543Z","iopub.status.idle":"2025-12-04T13:19:24.996944Z","shell.execute_reply.started":"2025-12-04T13:19:24.996752Z","shell.execute_reply":"2025-12-04T13:19:24.996769Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T13:19:24.998945Z","iopub.status.idle":"2025-12-04T13:19:24.999351Z","shell.execute_reply.started":"2025-12-04T13:19:24.999155Z","shell.execute_reply":"2025-12-04T13:19:24.999175Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Results <a class=\"anchor\"  id=\"results\"></a>\n\nIn order to achieve the creation of this final model with an accuracy score of 0.91, I had to make several trials.\n\n## Logistic Regression\n\nThe first step was to update the starter notebook to build a basic logistic regression model, which gave me a score of 0.75.\n\nThen, I added the cleaning process using regex. I removed the common labels in emails such as \"Subject:\" and \"re:\". I also removed the \"\\n\" at the end of the lines. This cleaning increased my score to 0.77.\n\nAfter that, I changed the tokenizer to use the best one I found when I did the tests in class: CountVector. It better my score with an accuracy of 0.80.\n\nThen, following what we did in class, I tried to remove the English stopwords. Yet it didn't help my model and made my accuracy score decrease to 0.79. Thus, I choose not to remove them.\n\nTo try everything I could with logistic regression, I tried to use another tokenizer: TdifVectorizer. I didn't have good results with it during the tests in class, but I read it was a good tokenizer. Unfortunately it gave me an accuracy score of 0.72, so I switched back to CountVetcor.\n\nThen, to improve the model, I tried to use a Naives Bayes classifier with a basic configuration, which resulted in an accuracy of 0.80.\n\nI wanted to try the different configuration for this tool. The first one was the sensibility to uncommon worlds.\n    - sensible to uncommon worlds    -> 0.77 accuracy\n    - unsensible to uncommon worlds -> 0.81 accuracy\nAt first, I thought making it sensible to uncommon worlds was important because in not-spam we could use some familiar worlds not in the vocabulary of spam. Yet, I guess, according to the results, that spams are becoming better to fool us with uncommon worlds.\n\nAnother configuration was to make the model influenced by the probability of classification. Which means that if there were more spam in training data, it would choose this option if it has a doubt. By default this option was set to true. I tried to switch it to false but it decreased my score to 0.76, thus I switched it back to true.\n\n## LSTM (Long Short-Term Memory)\n\nI tried all I could do with Logistic regression, so I wanted to try another model: LSTM (Long Short-Term Memory). I made a basic model using the cleaning process I built for logistic regression. At first, I only put 5 epochs. I obtained a score of 0.76.\n\nThere were not many things to do to improve the model apart from the number of epochs, thus I added 15 epochs. My accuracy score didn't change.\n\n## Transfer Learning\n\nThe last method I chose to try was Transfer Learning, since it worked well for image classification. Moreover, since our dataset is small, enlarging it with another train model seemed to be a great solution.\n\nAccording to websites, I found out that an excellent model for our problem of spam/not-spam classification was roBERTa. I applied it to the data, only with 2 epochs, and got an accuracy of 0.90.\n\nThen, I added 3 epochs improving my accuracy to 0.91.\n\nAdding more epochs after that didn't seem to improve my score and took several hours. Thus I stopped at 5 epochs.\n\nThe last test I wanted to do was to clean the data with my cleaning process. Yet it only reduced my accuracy score to 0.89","metadata":{}},{"cell_type":"markdown","source":"# Conclusion <a class=\"anchor\"  id=\"conclusion\"></a>\n\nThis experiment was really interesting, I learned to work with text data. I even tried more things than with image classification. \n\nI think I covered a large array of methods, but I know there are so many more for different classification, or multiple categories. I found it more interesting than image classification because I was able to understand better how it works.\n\nI ended up with an accuracy score of 0.91, which is really satisfying for me because I was blocked at 0.80 with the first models I used.\n\nI think that with even more trying and time, I could try more algorithms. I've read articles about so many other models and parameters for text classification.","metadata":{}},{"cell_type":"markdown","source":"# References <a class=\"anchor\"  id=\"references\"></a>\n\nGeek for geeks article about Text Classification - https://www.geeksforgeeks.org/nlp/what-is-text-classification/\n\nArticle about the different NLP models for Text Classification - https://mljourney.com/best-nlp-models-for-text-classification-in-2025/","metadata":{}}]}